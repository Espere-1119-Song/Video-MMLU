# Video-MMLU
A Massive Multi-Discipline Lecture Understanding Benchmark

<table><tr><td>
    <strong>AuroraCap</strong>: Efficient, Performant Video Detailed Captioning and a New Benchmark, ICLR, 2025.
</td></tr>
</table>

[![](https://img.shields.io/badge/AuroraCap-docs-922133)](docs/auroracap/README.md)
[![](https://img.shields.io/badge/web-922133)](https://rese1f.github.io/aurora-web/)
[![](http://img.shields.io/badge/arXiv-922133)](https://arxiv.org/abs/2410.03051)
[![](https://img.shields.io/badge/%F0%9F%A4%97%20_AuroraCap_model-ffc107?color=ffc107&logoColor=white)](https://huggingface.co/collections/wchai/auroracap-66d117ffe13bedda96702013)
[![](https://img.shields.io/badge/%F0%9F%A4%97%20_VDC_benchmark-ffc107?color=ffc107&logoColor=white)](https://huggingface.co/datasets/wchai/Video-Detailed-Caption)
[![](https://img.shields.io/badge/%F0%9F%A4%97%20_Trainset-ffc107?color=ffc107&logoColor=white)](https://huggingface.co/datasets/wchai/AuroraCap-trainset)


<img src="assets/auroracap/vdc_baseline.png" align="center">


**TODO**
## To-Do List

- [x] Release Arxiv version
- [x] Upload source video, detailed captions and QA pairs
- [x] Upload lmms-eval code
- [x] Upload VLMEvalkit code
- [ ] Upload figures_in_paper
- [ ] Upload the frame captions, video captions and the transcripts
- [ ] Upload keyframes


